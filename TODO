# To do

## Backlog

* ~~Helper function to increment filenames~~
* ~~Ensure outputs are cached to correct location of revised repo structure~~
* ~~Select a logging option to capture console output~~
* ~~Need pretty sessioninfo output for logging~~
* ~~Start logging with human friendly delimeter~~
* ~~added handle_query() function with logging output~~
* ~~added wrap_up() function for ending sequential ex of munge scripts~~
* ~~Query api and create equivalents of site.midas, site.tame and site.tmu data~~
* ~~Unit tests for site dataframes~~
* ~~Daily reports missing site IDs, inspect this in webtri.sh, may need to query one site at a time~~
* ~~Investigate issue with 07-join_readings_sites.R, no readings for tame or tmu sites...~~
* ~~querying siteIds - Use http_status to skip dataframe processing for anything returning $category == "Success" && $reason == "No content", certain siteIDs missing from provided api daterange~~
* ~~querying dateranges - need to establish api requirements and exception handling~~
* ~~Output a text file containing all sites that returned empty content for the specified date range~~
* ~~Combine the csvs in /data/ into `combo.csv`, as achieved in webtri.sh~~
* ~~Use this.path to demark all script start checkpoints~~
* ~~Add test logic for handing over: test_run == TRUE, only execute 1 day and first  site ID.~~

* DF insight for combo: review print statements for logging.
* Print count of missing IDs to log and to txt
* Print count of errorred IDs to log and to txt
* Print summaries of all status codes to log 
* Update to documentation - markdown web page with screengrabs
* handle_missing function requires unit testing.
* Unit testing all scripts
* remove api_logger
* Implement a retry for any internal server errors (HTTP status code 5**), script 07-GET_daily_reports.R stores these as retry_urls
* Implement partial data dump logic, when the cache file is partially populated due to an interrupted run, it would be more efficient to compare cached daily reports already ingested against those that are still outstanding. Pick up where we left off. 
* Use beepr::beep() for errors at common throttle points



## Performance
* Queried one day for all sites in 19.533 mins
Queried 31 days for all sites in Time difference of 1.216 hours