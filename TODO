# To do

## Backlog

* ~~Helper function to increment filenames~~
* ~~Ensure outputs are cached to correct location of revised repo structure~~
* ~~Select a logging option to capture console output~~
* ~~Need pretty sessioninfo output for logging~~
* ~~Start logging with human friendly delimeter~~
* ~~added handle_query() function with logging output~~
* ~~added wrap_up() function for ending sequential ex of munge scripts~~
* ~~Query api and create equivalents of site.midas, site.tame and site.tmu data~~
* ~~Unit tests for site dataframes~~
* ~~Daily reports missing site IDs, inspect this in webtri.sh, may need to query one site at a time~~
* ~~Investigate issue with 07-join_readings_sites.R, no readings for tame or tmu sites...~~
* ~~querying siteIds - Use http_status to skip dataframe processing for anything returning $category == "Success" && $reason == "No content", certain siteIDs missing from provided api daterange~~
* ~~querying dateranges - need to establish api requirements and exception handling~~
* ~~Output a text file containing all sites that returned empty content for the specified date range~~
* ~~Combine the csvs in /data/ into `combo.csv`, as achieved in webtri.sh~~
* ~~Use this.path to demark all script start checkpoints~~
* ~~Add test logic for handing over: test_run == TRUE, only execute 1 day and first  site ID.~~
* ~~document error: Error in fwrite(tmu, "output_data/tmu.csv", row.names = F, quote = F) : 
  Permission denied: 'output_data/tmu.csv'. Failed to open existing file for writing. Do you have write permission to it? Is this Windows and does another process such as Excel have it open?~~
* ~~Print count of missing IDs to log and to txt~~
* ~~Print count of errorred IDs to log and to txt~~
* ~~Print summaries of all status codes to log~~
* ~~Need to log all query parameters for use in replicating issues.~~
* ~~remove api_logger~~
* ~~Update to documentation - markdown web page with screengrabs~~
* ~~write filename behaviour specified by user: save output data files appended with query dates.~~

* Update func/functions.R labelling
* apply styler style guide
* date handling tests in 03-set_query_parameters.R
* parallel options
* Convert code to using joins with join interrogation
* DF insight for combo: review print statements for logging.
* handle_missing function requires unit testing.
* Unit testing all scripts
* Implement a retry for any internal server errors (HTTP status code 5**), script 07-GET_daily_reports.R stores these as retry_urls
* Implement partial data dump logic, when the cache file is partially populated due to an interrupted run, it would be more efficient to compare cached daily reports already ingested against those that are still outstanding. Pick up where we left off. 
* Use beepr::beep() for errors at common throttle points



## Performance
* Queried one day for all sites in 19.533 mins
Queried 31 days for all sites in Time difference of 1.216 hours