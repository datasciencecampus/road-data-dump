# To do

### Backlog

* Email auto complete - look into shinystore on github, prefer something on CRAN, HTML5 local store equiv, typeahead...
* cicerone guide
* shiny helper
* Update documentation
* Date checks in script
* Grey out elements when testing?
* Daterange selection instead?
* bug test Email validation check - once successful status detected, is sticky.
* Tidy up environment from final sequential script forwards.
* Implement UI for setting query parameters.
* Remove all missing report.txt logic or move to logs.
* Implement partial data dump logic, when the cache file is partially populated due to an interrupted run, it would be more efficient to compare cached daily reports already ingested against those that are still outstanding. Pick up where we left off.
* present df head in UI on successful completion



### Performance

* 2 days (1st to 2nd Sep 2020) takes: Time difference of 5.679 mins, 3.6 times faster using parallel compute.
* Scale up to 1 month, previously took 2.25 hrs for Sep 2020.
* Queried 31 days for all sites in Time difference of 52.702 mins
* 2.6 times faster using parallel compute. Comes at a cost though - requires additional RAM, from 20GB up to 30GB.